{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from prophet import Prophet\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "from csv import writer\n",
    "from datetime import datetime, timedelta\n",
    "import emoji\n",
    "# import streamlit_authenticator as stauth \n",
    "import schedule     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk melakukan scraping data\n",
    "def scrape_data(start_date, end_date):\n",
    "    bulan = {\n",
    "        1: \"Januari\",\n",
    "        2: \"Februari\",\n",
    "        3: \"Maret\",\n",
    "        4: \"April\",\n",
    "        5: \"Mei\",\n",
    "        6: \"Juni\",\n",
    "        7: \"Juli\",\n",
    "        8: \"Agustus\",\n",
    "        9: \"September\",\n",
    "        10: \"Oktober\",\n",
    "        11: \"November\",\n",
    "        12: \"Desember\"\n",
    "    }\n",
    "    data_list = []\n",
    "    for date in pd.date_range(start_date, end_date):\n",
    "        month_name_id = bulan[date.month]\n",
    "        url_day = f\"https://harga-emas.org/history-harga/{date.year}/{month_name_id}/{date.day}/\"\n",
    "        page = requests.get(url_day)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        lists = soup.find('div', class_='col-md-8')\n",
    "        row_data = [date.strftime('%Y-%m-%d')]\n",
    "        index = 0\n",
    "        for item in lists.findAll('tr'):\n",
    "            index += 1\n",
    "            if index == 21:\n",
    "                base_value = item.findAll('b')\n",
    "                index_core = 0\n",
    "                for core in base_value:\n",
    "                    index_core += 1\n",
    "                    if index_core == 2:\n",
    "                        value = core.text.split('+')[0].split('-')[0].split('(')[0]\n",
    "                        value = value.replace('.', '').strip()\n",
    "                        value = value.replace('Rp', '').strip()\n",
    "                        value = value.replace('/', '').strip()\n",
    "                        value = value.replace('gram', '').strip()\n",
    "                        row_data.append(value)\n",
    "        data_list.append(row_data)\n",
    "        time.sleep(1)  # Jeda untuk mencegah terlalu banyak permintaan ke website\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(data_list, file_name):\n",
    "    with open(file_name, 'a', newline='') as file:\n",
    "        csv_writer = writer(file)\n",
    "        csv_writer.writerows(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_dan_simpan():\n",
    "    # Baca tanggal terakhir dari file CSV\n",
    "    file_name = 'data/harga_emas.csv'\n",
    "    df5 = pd.read_csv(file_name)\n",
    "    last_date_str = df5.iloc[-1]['Tanggal']\n",
    "    last_date = datetime.strptime(last_date_str, '%Y-%m-%d').date()\n",
    "        \n",
    "    start_date = last_date + timedelta(days=1)\n",
    "    end_date = datetime.now().date()\n",
    "        \n",
    "    if start_date <= end_date:\n",
    "        # Scraping data dan menyimpannya ke dalam file CSV\n",
    "        data_list = scrape_data(start_date, end_date)\n",
    "        save_to_csv(data_list, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('data/harga_emas.csv')\n",
    "df['Tanggal'] = pd.to_datetime(df['Tanggal'])\n",
    "df['Tanggal'] = df['Tanggal'].dt.date\n",
    "df.set_index('Tanggal', inplace=True)\n",
    "df['Harga'] = (df['Price5'])\n",
    "print(df.dtypes)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dropna(inplace = True)\n",
    "# df.reset_index(inplace = True)\n",
    "df.drop(['Price1', 'Price2', 'Price3', 'Price5', 'Price10', 'Price25', 'Price50', 'Price100'], axis=1, inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = df.iloc[:, 0:1] #.values\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "data_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning / Preprocessing data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "data_set_scaled = sc.fit_transform(data_set)\n",
    "print(data_set_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple features from data provided to the model\n",
    "X = []\n",
    "backcandles = 30 # Jumlah hari mundur / kebelakang\n",
    "print(data_set_scaled.shape[0])\n",
    "for j in range(1): # jumlah kolom = 8\n",
    "  X.append([])\n",
    "  for i in range(backcandles, data_set_scaled.shape[0]):\n",
    "    X[j].append(data_set_scaled[i - backcandles:i, j])\n",
    "\n",
    "X = np.moveaxis(X, [0], [2])\n",
    "\n",
    "# -1 untuk memilih kolom terakhir\n",
    "X, yi = np.array(X), np.array(data_set_scaled[backcandles:, -1])\n",
    "y=np.reshape(yi,(len(yi),1))\n",
    "# y = yi.reshape(-1, 1)\n",
    "\n",
    "print(X.shape)\n",
    "print(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train test sets\n",
    "splitlimit = int(len(X)*0.8)\n",
    "print(splitlimit)\n",
    "\n",
    "X_train, X_test = X[:splitlimit], X[splitlimit:]\n",
    "y_train, y_test = y[:splitlimit], y[splitlimit:]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.callbacks import History\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, LSTM, Input, Activation, concatenate, TimeDistributed\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('WebAgg')\n",
    "# from matplotlib.figure import Figure\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# backcandles = 30\n",
    "\n",
    "lstm_input = Input(shape=(backcandles, 1), name=\"lstm_input\")\n",
    "inputs = LSTM(150, name=\"first_layer\")(lstm_input)\n",
    "inputs = Dense(1, name=\"dense_layer\")(inputs)\n",
    "output = Activation('linear', name=\"output\")(inputs)\n",
    "model = Model(inputs=lstm_input, outputs=output)\n",
    "adam = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=adam, loss='mse')\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_train dtype:\", X_train.dtype)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_train dtype:\", y_train.dtype)\n",
    "\n",
    "model_test = model.fit(x=X_train, y=y_train, batch_size=30, epochs=30, shuffle=True, validation_split=0.1)\n",
    "\n",
    "plt.close('all')\n",
    "plt.plot(model_test.history['loss'])\n",
    "plt.plot(model_test.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_pred = model.predict(X_test)\n",
    "for i in range(10):\n",
    "  print(y_pred[i], y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# MSE\n",
    "mse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"MSE score: \", mse)\n",
    "\n",
    "# RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE score: \", rmse)\n",
    "\n",
    "# MAE\n",
    "mae = np.sqrt(mean_absolute_error(y_test, y_pred))\n",
    "print(\"MAE score: \", mae)\n",
    "\n",
    "#R2\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"r2_score: \", r2)\n",
    "\n",
    "def mean_absolute_percentage_error(y_test, y_pred):\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_pred)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(\"MAPE: \", mape, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(y_test, color=\"red\", label=\"Test\")\n",
    "plt.plot(y_pred, color=\"blue\", label=\"Prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last backcandles days' price\n",
    "last_backandles_prices = data_set_scaled[-backcandles:]\n",
    "\n",
    "# Reshape the data to match the modul input shape\n",
    "last_backandles_prices = last_backandles_prices.reshape((1, backcandles, 1))\n",
    "\n",
    "# Predict tomorrow's price\n",
    "predicted_tomorrow_price = model.predict(last_backandles_prices)\n",
    "\n",
    "# Inverse transform the predicted price to get the actual price\n",
    "predicted_tomorrow_price = sc.inverse_transform(predicted_tomorrow_price)\n",
    "\n",
    "print(\"Tomorrow's price: \", predicted_tomorrow_price[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
