{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'batch_size': 20, 'epochs': 30, 'model__dropout_rate': 0.2, 'model__learning_rate': 0.001, 'model__lstm_units': 100}\n",
      "Best Score: 0.9607191895856039\n"
     ]
    }
   ],
   "source": [
    "from gc import callbacks\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import History\n",
    "from keras.optimizers import Adam\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib\n",
    "matplotlib.use('WebAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "\n",
    "# Load your dataset\n",
    "gold_price_data = pd.read_csv('data/harga_emas_new2.csv')\n",
    "gold_price_data['Tanggal'] = pd.to_datetime(gold_price_data['Tanggal'])\n",
    "gold_price_data.set_index('Tanggal', inplace=True)\n",
    "\n",
    "gold_price_data['Harga'] = gold_price_data['Price1'].astype(str).str.replace('.', '').astype(float)\n",
    "gold_price_data.drop(['Price1', 'Price2', 'Price3', 'Price5', 'Price10', 'Price25', 'Price50', 'Price100'], axis=1, inplace=True)\n",
    "\n",
    "# Preprocess your dataset\n",
    "def preprocess_data(df, look_back):\n",
    "    data = df['Harga'].values\n",
    "    data = data.reshape(-1, 1)\n",
    "    \n",
    "    # Normalize the dataset\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    data = scaler.fit_transform(data)\n",
    "\n",
    "    train_size = int(len(data) * 0.8)\n",
    "    train, test = data[0:train_size], data[train_size:len(data)]\n",
    "\n",
    "    def create_dataset(dataset, look_back=1):\n",
    "        X, Y = [], []\n",
    "        for i in range(len(dataset) - look_back - 1):\n",
    "            a = dataset[i:(i + look_back), 0]\n",
    "            X.append(a)\n",
    "            Y.append(dataset[i + look_back, 0])\n",
    "        return np.array(X), np.array(Y)\n",
    "\n",
    "    trainX, trainY = create_dataset(train, look_back)\n",
    "    testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "    # Reshape input to be [samples, time steps, features]\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], look_back, 1))\n",
    "    testX = np.reshape(testX, (testX.shape[0], look_back, 1))\n",
    "\n",
    "    return trainX, trainY, testX, testY, scaler\n",
    "\n",
    "look_back = 10  # Adjust based on your requirements\n",
    "trainX, trainY, testX, testY, scaler = preprocess_data(gold_price_data, look_back)\n",
    "\n",
    "# Define the function to create the model\n",
    "def create_model(lstm_units=150, learning_rate=0.001, dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_units, return_sequences=True, input_shape=(look_back, 1)))\n",
    "    model.add(LSTM(lstm_units // 2, return_sequences=False))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'model__lstm_units': [100, 150, 200],\n",
    "    'model__learning_rate': [0.001, 0.01],\n",
    "    'model__dropout_rate': [0.2, 0.3],\n",
    "    'batch_size': [20, 30, 50],\n",
    "    'epochs': [30]\n",
    "}\n",
    "\n",
    "# model_path = 'saved_test_model/model.h5'\n",
    "\n",
    "# Create the KerasRegressor\n",
    "model = KerasRegressor(model=create_model, verbose=0)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the GridSearchCV\n",
    "history = History()\n",
    "grid_result = grid.fit(trainX, trainY, callbacks=[history])\n",
    "\n",
    "# grid_result.save(model_path)\n",
    "\n",
    "# Print the best parameters\n",
    "print(f\"Best Parameters: {grid_result.best_params_}\")\n",
    "print(f\"Best Score: {grid_result.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plot the training and validation loss of the best model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_result\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mhistory\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "# Plot the training and validation loss of the best model\n",
    "best_model = grid_result.best_estimator_.model\n",
    "history = best_model.history\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
