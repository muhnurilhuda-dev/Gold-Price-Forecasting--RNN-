{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from prophet import Prophet\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "from csv import writer\n",
    "from datetime import datetime, timedelta\n",
    "import emoji\n",
    "# import streamlit_authenticator as stauth \n",
    "import schedule     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk melakukan scraping data\n",
    "def scrape_data(start_date, end_date):\n",
    "    bulan = {\n",
    "        1: \"Januari\",\n",
    "        2: \"Februari\",\n",
    "        3: \"Maret\",\n",
    "        4: \"April\",\n",
    "        5: \"Mei\",\n",
    "        6: \"Juni\",\n",
    "        7: \"Juli\",\n",
    "        8: \"Agustus\",\n",
    "        9: \"September\",\n",
    "        10: \"Oktober\",\n",
    "        11: \"November\",\n",
    "        12: \"Desember\"\n",
    "    }\n",
    "    data_list = []\n",
    "    for date in pd.date_range(start_date, end_date):\n",
    "        month_name_id = bulan[date.month]\n",
    "        url_day = f\"https://harga-emas.org/history-harga/{date.year}/{month_name_id}/{date.day}/\"\n",
    "        page = requests.get(url_day)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        lists = soup.find('div', class_='col-md-8')\n",
    "        row_data = [date.strftime('%Y-%m-%d')]\n",
    "        index = 0\n",
    "        for item in lists.findAll('tr'):\n",
    "            index += 1\n",
    "            if index == 21:\n",
    "                base_value = item.findAll('b')\n",
    "                index_core = 0\n",
    "                for core in base_value:\n",
    "                    index_core += 1\n",
    "                    if index_core == 2:\n",
    "                        value = core.text.split('+')[0].split('-')[0].split('(')[0]\n",
    "                        value = value.replace('.', '').strip()\n",
    "                        value = value.replace('Rp', '').strip()\n",
    "                        value = value.replace('/', '').strip()\n",
    "                        value = value.replace('gram', '').strip()\n",
    "                        row_data.append(value)\n",
    "        data_list.append(row_data)\n",
    "        time.sleep(1)  # Jeda untuk mencegah terlalu banyak permintaan ke website\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(data_list, file_name):\n",
    "    with open(file_name, 'a', newline='') as file:\n",
    "        csv_writer = writer(file)\n",
    "        csv_writer.writerows(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_dan_simpan():\n",
    "    # Baca tanggal terakhir dari file CSV\n",
    "    file_name = 'data/harga_emas.csv'\n",
    "    df5 = pd.read_csv(file_name)\n",
    "    last_date_str = df5.iloc[-1]['Tanggal']\n",
    "    last_date = datetime.strptime(last_date_str, '%Y-%m-%d').date()\n",
    "        \n",
    "    start_date = last_date + timedelta(days=1)\n",
    "    end_date = datetime.now().date()\n",
    "        \n",
    "    if start_date <= end_date:\n",
    "        # Scraping data dan menyimpannya ke dalam file CSV\n",
    "        data_list = scrape_data(start_date, end_date)\n",
    "        save_to_csv(data_list, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price100    int64\n",
      "Price50     int64\n",
      "Price25     int64\n",
      "Price10     int64\n",
      "Price5      int64\n",
      "Price3      int64\n",
      "Price2      int64\n",
      "Price1      int64\n",
      "Harga       int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price100</th>\n",
       "      <th>Price50</th>\n",
       "      <th>Price25</th>\n",
       "      <th>Price10</th>\n",
       "      <th>Price5</th>\n",
       "      <th>Price3</th>\n",
       "      <th>Price2</th>\n",
       "      <th>Price1</th>\n",
       "      <th>Harga</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tanggal</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>48550000</td>\n",
       "      <td>24300000</td>\n",
       "      <td>12175000</td>\n",
       "      <td>4900000</td>\n",
       "      <td>2475000</td>\n",
       "      <td>1494000</td>\n",
       "      <td>1008000</td>\n",
       "      <td>524000</td>\n",
       "      <td>524000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02</th>\n",
       "      <td>49150000</td>\n",
       "      <td>24600000</td>\n",
       "      <td>12325000</td>\n",
       "      <td>4960000</td>\n",
       "      <td>2505000</td>\n",
       "      <td>1512000</td>\n",
       "      <td>1020000</td>\n",
       "      <td>530000</td>\n",
       "      <td>530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-03</th>\n",
       "      <td>49350000</td>\n",
       "      <td>24700000</td>\n",
       "      <td>12375000</td>\n",
       "      <td>4980000</td>\n",
       "      <td>2515000</td>\n",
       "      <td>1518000</td>\n",
       "      <td>1024000</td>\n",
       "      <td>532000</td>\n",
       "      <td>532000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-04</th>\n",
       "      <td>49350000</td>\n",
       "      <td>24700000</td>\n",
       "      <td>12375000</td>\n",
       "      <td>4980000</td>\n",
       "      <td>2515000</td>\n",
       "      <td>1518000</td>\n",
       "      <td>1024000</td>\n",
       "      <td>532000</td>\n",
       "      <td>532000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-05</th>\n",
       "      <td>49350000</td>\n",
       "      <td>24700000</td>\n",
       "      <td>12375000</td>\n",
       "      <td>4980000</td>\n",
       "      <td>2515000</td>\n",
       "      <td>1518000</td>\n",
       "      <td>1024000</td>\n",
       "      <td>532000</td>\n",
       "      <td>532000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Price100   Price50   Price25  Price10   Price5   Price3   Price2  \\\n",
       "Tanggal                                                                        \n",
       "2014-01-01  48550000  24300000  12175000  4900000  2475000  1494000  1008000   \n",
       "2014-01-02  49150000  24600000  12325000  4960000  2505000  1512000  1020000   \n",
       "2014-01-03  49350000  24700000  12375000  4980000  2515000  1518000  1024000   \n",
       "2014-01-04  49350000  24700000  12375000  4980000  2515000  1518000  1024000   \n",
       "2014-01-05  49350000  24700000  12375000  4980000  2515000  1518000  1024000   \n",
       "\n",
       "            Price1   Harga  \n",
       "Tanggal                     \n",
       "2014-01-01  524000  524000  \n",
       "2014-01-02  530000  530000  \n",
       "2014-01-03  532000  532000  \n",
       "2014-01-04  532000  532000  \n",
       "2014-01-05  532000  532000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('data/harga_emas.csv')\n",
    "df['Tanggal'] = pd.to_datetime(df['Tanggal'])\n",
    "df['Tanggal'] = df['Tanggal'].dt.date\n",
    "df.set_index('Tanggal', inplace=True)\n",
    "df['Harga'] = (df['Price1'])\n",
    "print(df.dtypes)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Harga</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tanggal</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>524000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02</th>\n",
       "      <td>530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-03</th>\n",
       "      <td>532000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-04</th>\n",
       "      <td>532000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-05</th>\n",
       "      <td>532000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Harga\n",
       "Tanggal           \n",
       "2014-01-01  524000\n",
       "2014-01-02  530000\n",
       "2014-01-03  532000\n",
       "2014-01-04  532000\n",
       "2014-01-05  532000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.dropna(inplace = True)\n",
    "# df.reset_index(inplace = True)\n",
    "df.drop(['Price1', 'Price2', 'Price3', 'Price5', 'Price10', 'Price25', 'Price50', 'Price100'], axis=1, inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load data lagi\n",
    "# df2 = pd.read_csv('data/harga_emas.csv')\n",
    "# df2['Tanggal'] = pd.to_datetime(df2['Tanggal'])\n",
    "# df2.set_index('Tanggal', inplace=True)\n",
    "# print(df2.dtypes)\n",
    "# df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dropna(inplace = True)\n",
    "# df.reset_index(inplace = True)\n",
    "# df2.drop(['Price1', 'Price2', 'Price3', 'Price5', 'Price10', 'Price25', 'Price50', 'Price100'], axis=1, inplace=True)\n",
    "# df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Harga</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tanggal</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>524000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02</th>\n",
       "      <td>530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-03</th>\n",
       "      <td>532000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-04</th>\n",
       "      <td>532000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-05</th>\n",
       "      <td>532000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Harga\n",
       "Tanggal           \n",
       "2014-01-01  524000\n",
       "2014-01-02  530000\n",
       "2014-01-03  532000\n",
       "2014-01-04  532000\n",
       "2014-01-05  532000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = df.iloc[:, 0:1] #.values\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "data_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0094451 ]\n",
      " [0.01652893]\n",
      " [0.0188902 ]\n",
      " ...\n",
      " [0.95513577]\n",
      " [0.95749705]\n",
      " [0.95749705]]\n"
     ]
    }
   ],
   "source": [
    "# Learning / Preprocessing data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "data_set_scaled = sc.fit_transform(data_set)\n",
    "print(data_set_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4681\n",
      "(4651, 30, 1)\n",
      "[[0.02715466]\n",
      " [0.02715466]\n",
      " [0.02715466]\n",
      " ...\n",
      " [0.95513577]\n",
      " [0.95749705]\n",
      " [0.95749705]]\n",
      "(4651, 1)\n"
     ]
    }
   ],
   "source": [
    "# Multiple features from data provided to the model\n",
    "X = []\n",
    "backcandles = 30 # Jumlah hari mundur / kebelakang\n",
    "print(data_set_scaled.shape[0])\n",
    "for j in range(1): # jumlah kolom = 8\n",
    "  X.append([])\n",
    "  for i in range(backcandles, data_set_scaled.shape[0]):\n",
    "    X[j].append(data_set_scaled[i - backcandles:i, j])\n",
    "\n",
    "X = np.moveaxis(X, [0], [2])\n",
    "\n",
    "# -1 untuk memilih kolom terakhir\n",
    "X, yi = np.array(X), np.array(data_set_scaled[backcandles:, -1])\n",
    "y=np.reshape(yi,(len(yi),1))\n",
    "# y = yi.reshape(-1, 1)\n",
    "\n",
    "print(X.shape)\n",
    "print(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3720\n",
      "(3720, 30, 1)\n",
      "(931, 30, 1)\n",
      "(3720, 1)\n",
      "(931, 1)\n",
      "(4651, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train test sets\n",
    "splitlimit = int(len(X)*0.8)\n",
    "print(splitlimit)\n",
    "\n",
    "X_train, X_test = X[:splitlimit], X[splitlimit:]\n",
    "y_train, y_test = y[:splitlimit], y[splitlimit:]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import keras\n",
    "# from keras import optimizers\n",
    "# from keras.callbacks import History\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Dense, Dropout, LSTM, Input, Activation, concatenate, TimeDistributed\n",
    "# import numpy as np\n",
    "# import matplotlib\n",
    "# matplotlib.use('WebAgg')\n",
    "# # from matplotlib.figure import Figure\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # backcandles = 30\n",
    "\n",
    "# lstm_input = Input(shape=(backcandles, 1), name=\"lstm_input\")\n",
    "# print(\"Backcandles: \", + backcandles)\n",
    "# inputs = LSTM(150, name=\"first_layer\")(lstm_input)\n",
    "# inputs = Dense(1, name=\"dense_layer\")(inputs)\n",
    "# inputs = Dropout(0.2)(inputs)\n",
    "# output = Activation('linear', name=\"output\")(inputs)\n",
    "# model = Model(inputs=lstm_input, outputs=output)\n",
    "# adam = optimizers.Adam(learning_rate=0.001)\n",
    "# model.compile(optimizer=adam, loss='mse')\n",
    "\n",
    "# print(\"X_train shape:\", X_train.shape)\n",
    "# print(\"X_train dtype:\", X_train.dtype)\n",
    "# print(\"y_train shape:\", y_train.shape)\n",
    "# print(\"y_train dtype:\", y_train.dtype)\n",
    "\n",
    "# model_test = model.fit(x=X_train, y=y_train, batch_size=15, epochs=30, shuffle=True, validation_split=0.1)\n",
    "\n",
    "# plt.close('all')\n",
    "# plt.plot(model_test.history['loss'])\n",
    "# plt.plot(model_test.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'validation'], loc='upper right')\n",
    "# plt.show()\n",
    "# # plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3720, 30, 1)\n",
      "X_train dtype: float64\n",
      "y_train shape: (3720, 1)\n",
      "y_train dtype: float64\n",
      "Epoch 1/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.0114 - val_loss: 0.0013\n",
      "Epoch 2/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 3/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 7.6633e-04 - val_loss: 0.0019\n",
      "Epoch 4/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.0771e-04 - val_loss: 9.4746e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.9516e-04 - val_loss: 0.0023\n",
      "Epoch 6/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.2102e-04 - val_loss: 8.1071e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.5920e-04 - val_loss: 6.7169e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.2042e-04 - val_loss: 0.0016\n",
      "Epoch 9/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.5925e-04 - val_loss: 6.3007e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.3198e-04 - val_loss: 5.7281e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.8258e-04 - val_loss: 8.4920e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.8506e-04 - val_loss: 5.2633e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.5016e-04 - val_loss: 6.7421e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.3553e-04 - val_loss: 9.0990e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.4019e-04 - val_loss: 7.7199e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.8091e-04 - val_loss: 5.3405e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.6931e-04 - val_loss: 4.9846e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.2433e-04 - val_loss: 4.8555e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.4197e-04 - val_loss: 4.6993e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.5557e-04 - val_loss: 4.6333e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.7338e-04 - val_loss: 5.0167e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.8052e-04 - val_loss: 4.9042e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.2799e-04 - val_loss: 5.0202e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.6173e-04 - val_loss: 5.0580e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.0119e-04 - val_loss: 4.3448e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.7105e-04 - val_loss: 5.7002e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.4411e-04 - val_loss: 4.3582e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.0672e-04 - val_loss: 4.2492e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.8700e-04 - val_loss: 4.1536e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.5089e-04 - val_loss: 4.0583e-04\n"
     ]
    }
   ],
   "source": [
    "# MANUAL HYPERPARAMETERS TUNING\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, LSTM, Input, Activation\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('WebAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hyperparameters to tune\n",
    "backcandles = 30  # Assuming 30 time steps\n",
    "lstm_units = 150  # Start with 150, tune this value\n",
    "learning_rate = 0.001  # Start with 0.001, tune this value\n",
    "batch_size = 30  # Start with 15, tune this value\n",
    "epochs = 30  # Start with 30, tune this value\n",
    "dropout_rate = 0.2  # Start with 0.2, tune this value\n",
    "\n",
    "lstm_input = Input(shape=(backcandles, 1), name=\"lstm_input\")\n",
    "inputs = LSTM(lstm_units, name=\"first_layer\")(lstm_input)\n",
    "inputs = Dropout(dropout_rate)(inputs)  # Added dropout layer\n",
    "inputs = Dense(1, name=\"dense_layer\")(inputs)\n",
    "output = Activation('linear', name=\"output\")(inputs)\n",
    "model = Model(inputs=lstm_input, outputs=output)\n",
    "\n",
    "adam = optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=adam, loss='mse')\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_train dtype:\", X_train.dtype)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_train dtype:\", y_train.dtype)\n",
    "\n",
    "model_test = model.fit(x=X_train, y=y_train, batch_size=batch_size, epochs=epochs, shuffle=True, validation_split=0.1)\n",
    "\n",
    "plt.close('all')\n",
    "plt.plot(model_test.history['loss'])\n",
    "plt.plot(model_test.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # AUTOMATIC HYPERPARAMETERS TUNING\n",
    "\n",
    "# # from gc import callbacks\n",
    "# import tensorflow as tf\n",
    "# # from keras import Sequential, callbacks\n",
    "# # from keras.layers import Dense, Dropout, LSTM, Input, Activation\n",
    "# # from keras import optimizers\n",
    "\n",
    "# # def build_model(hp):\n",
    "# #     model = Sequential()\n",
    "# #     model.add(LSTM(units=hp.Int('units', min_value=50, max_value=300, step=50), input_shape=(backcandles, 1)))\n",
    "# #     model.add(Dropout(rate=hp.Float('dropout', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "# #     model.add(Dense(1))\n",
    "# #     model.add(Activation('linear'))\n",
    "\n",
    "# #     model.compile(optimizer=optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[0.001, 0.0001])),\n",
    "# #                   loss='mse')\n",
    "# #     return model\n",
    "\n",
    "# def model_builder(hp):\n",
    "#   model = tf.keras.Sequential()\n",
    "#   model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "#   hp_activation = hp.Choice('activation', values=['relu', 'tanh'])\n",
    "#   hp_layer_1 = hp.Int('layer_1', min_value=1, max_value=1000, step=100)\n",
    "#   hp_layer_2 = hp.Int('layer_2', min_value=1, max_value=1000, step=100)\n",
    "#   hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "#   model.add(tf.keras.layers.Dense(units=hp_layer_1, activation=hp_activation))\n",
    "#   model.add(tf.keras.layers.Dense(units=hp_layer_2, activation=hp_activation))\n",
    "#   model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "#   model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "#                 loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "#                 metrics=['accuracy'])\n",
    "  \n",
    "#   return model\n",
    "\n",
    "\n",
    "# # tuner = kt.Hyperband(build_model,\n",
    "# #                      objective='val_loss',\n",
    "# #                      max_epochs=15,\n",
    "# #                      factor=3,\n",
    "# #                      directory='my_dir',\n",
    "# #                      project_name='intro_to_kt')\n",
    "\n",
    "# import keras_tuner as kt\n",
    "\n",
    "# tuner = kt.Hyperband(model_builder,\n",
    "#                      objective='val_accuracy',\n",
    "#                      max_epochs=10,\n",
    "#                      factor=3,\n",
    "#                      directory='dir',\n",
    "#                      project_name='x')\n",
    "\n",
    "# # stop_early = callbacks.EarlyStopping(monitor=\"val_loss\", patience = 3)\n",
    "# stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "# tuner.search(x=X_train, y=y_train, epochs=30, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "\n",
    "# # Get the optimal hyperparameters\n",
    "# best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# print(f\"\"\"\n",
    "# The optimal number of units in the first LSTM layer is {best_hps.get('units')}.\n",
    "# The optimal dropout rate is {best_hps.get('dropout')}.\n",
    "# The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\n",
    "# \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# from sqlalchemy import values\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Dense, Dropout, LSTM, Input, Activation\n",
    "# from tensorflow.keras import optimizers\n",
    "# import numpy as np\n",
    "# import matplotlib\n",
    "# matplotlib.use('WebAgg')\n",
    "# import matplotlib.pyplot as plt\n",
    "# import keras_tuner as kt\n",
    "\n",
    "# # Example data (replace with your actual data)\n",
    "# # X_train = np.random.rand(3740, 30, 1)\n",
    "# # y_train = np.random.rand(3740, 1)\n",
    "\n",
    "# # Hyperparameter tuning function\n",
    "# def build_model(hp):\n",
    "#     lstm_units = hp.Int('units', min_value=50, max_value=300, step=50)\n",
    "#     batch_size = hp.Int('batch_size', min_value=10, max_value=1000, step=10)\n",
    "#     dropout_rate = hp.Float('dropout', min_value=0.1, max_value=0.5, step=0.1)\n",
    "#     learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "#     activation = hp.Choice('activation', values=['relu', 'tanh'])\n",
    "    \n",
    "#     lstm_input = Input(shape=(30, 1), name=\"lstm_input\")\n",
    "#     inputs = LSTM(lstm_units, name=\"first_layer\")(lstm_input)\n",
    "#     inputs = Dropout(dropout_rate)(inputs)\n",
    "#     inputs = Dense(1, name=\"dense_layer\")(inputs)\n",
    "#     # inputs = Activation(activation)\n",
    "#     # inputs = batch_size\n",
    "#     output = Activation('linear', name=\"output\")(inputs)\n",
    "#     model = Model(inputs=lstm_input, outputs=output)\n",
    "    \n",
    "#     adam = optimizers.Adam(learning_rate=learning_rate)\n",
    "#     # model.compile(optimizer=adam, loss='mse')\n",
    "#     model.compile(optimizer=adam, loss='mse', metrics=['accuracy'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# # Set up the tuner\n",
    "# # tuner = kt.RandomSearch(\n",
    "# tuner = kt.Hyperband(\n",
    "#     build_model,\n",
    "#     objective='val_loss',\n",
    "#     max_epochs=30,\n",
    "#     factor=3,\n",
    "#     executions_per_trial=1,\n",
    "#     directory='my_dir',\n",
    "#     project_name='lstm_tuning',\n",
    "#     overwrite=True,\n",
    "# )\n",
    "\n",
    "# # def model_builder(hp):\n",
    "# #   model = tf.keras.Sequential()\n",
    "# #   # model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# #   hp_activation = hp.Choice('activation', values=['relu', 'tanh'])\n",
    "# #   hp_layer_1 = hp.Int('layer_1', min_value=1, max_value=1000, step=100)\n",
    "# #   hp_layer_2 = hp.Int('layer_2', min_value=1, max_value=1000, step=100)\n",
    "# #   hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "# #   model.add(tf.keras.layers.Dense(units=hp_layer_1, activation=hp_activation))\n",
    "# #   model.add(tf.keras.layers.Dense(units=hp_layer_2, activation=hp_activation))\n",
    "# #   model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# #   model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "# #                 loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "# #                 metrics=['accuracy'])\n",
    "  \n",
    "# #   return model\n",
    "\n",
    "# # import keras_tuner as kt\n",
    "\n",
    "# # tuner = kt.Hyperband(model_builder,\n",
    "# #                      objective='val_accuracy',\n",
    "# #                      max_epochs=10,\n",
    "# #                      factor=3,\n",
    "# #                      directory='dir',\n",
    "# #                      project_name='x')\n",
    "\n",
    "# # Display search space summary\n",
    "# tuner.search_space_summary()\n",
    "\n",
    "# # Define the EarlyStopping callback\n",
    "# stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# # Perform the hyperparameter search\n",
    "# # tuner.search(x=X_train, y=y_train, epochs=30, validation_split=0.2, callbacks=[stop_early])\n",
    "# tuner.search(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     epochs=30,\n",
    "#     validation_split=0.2,\n",
    "#     callbacks=[stop_early],\n",
    "#     # batch_size=kt.In('batch_size', min_value=10, max_value=1000, step=10)\n",
    "# )\n",
    "\n",
    "# # Retrieve the best model and hyperparameters\n",
    "# best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# print(f\"\"\"\n",
    "# The optimal number of units in the first LSTM layer is {best_hps.get('units')}.\n",
    "# The optimal dropout rate is {best_hps.get('dropout')}.\n",
    "# The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\n",
    "# \"\"\")\n",
    "\n",
    "# # Build the best model\n",
    "# model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# # Getting the most optimal batch_size\n",
    "# optimal_batch_size = best_hps.get('batch_size')\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     epochs=30,\n",
    "#     validation_split=0.1,\n",
    "#     # batch_size=best_hps.get('batch_size'),\n",
    "#     batch_size=optimal_batch_size,\n",
    "#     callbacks=[stop_early]\n",
    "# )\n",
    "\n",
    "# # Plot the results\n",
    "# plt.close('all')\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('Model Loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build the best model\n",
    "# model = tuner.hypermodel.build(best_hps)\n",
    "# history = model.fit(X_train, y_train, epochs=30, validation_split=0.1, callbacks=['stop_early'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Dense, Dropout, LSTM, Input, Activation\n",
    "# from keras import optimizers\n",
    "# import numpy as np\n",
    "# import matplotlib\n",
    "# matplotlib.use('WebAgg')\n",
    "# import matplotlib.pyplot as plt\n",
    "# from keras_tuner import RandomSearch\n",
    "\n",
    "# # Example data (replace with your actual data)\n",
    "# # X_train = np.random.rand(3740, 30, 1)\n",
    "# # y_train = np.random.rand(3740, 1)\n",
    "\n",
    "# # Hyperparameter tuning function\n",
    "# def build_model(hp):\n",
    "#     lstm_units = hp.Int('units', min_value=50, max_value=300, step=50)\n",
    "#     dropout_rate = hp.Float('dropout', min_value=0.1, max_value=0.5, step=0.1)\n",
    "#     learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "#     lstm_input = Input(shape=(30, 1), name=\"lstm_input\")\n",
    "#     inputs = LSTM(lstm_units, name=\"first_layer\")(lstm_input)\n",
    "#     inputs = Dropout(dropout_rate)(inputs)\n",
    "#     inputs = Dense(1, name=\"dense_layer\")(inputs)\n",
    "#     output = Activation('linear', name=\"output\")(inputs)\n",
    "#     model = Model(inputs=lstm_input, outputs=output)\n",
    "    \n",
    "#     adam = optimizers.Adam(learning_rate=learning_rate)\n",
    "#     model.compile(optimizer=adam, loss='mse')\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# # Set up the tuner\n",
    "# tuner = RandomSearch(\n",
    "#     build_model,\n",
    "#     objective='val_loss',\n",
    "#     max_trials=10,\n",
    "#     executions_per_trial=1,\n",
    "#     directory='my_dir',\n",
    "#     project_name='lstm_tuning'\n",
    "# )\n",
    "\n",
    "# # Display search space summary\n",
    "# tuner.search_space_summary()\n",
    "\n",
    "# # Perform the hyperparameter search\n",
    "# tuner.search(X_train, y_train, epochs=30, validation_split=0.1)\n",
    "\n",
    "# # Retrieve the best model and hyperparameters\n",
    "# best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# print(f\"\"\"\n",
    "# The optimal number of units in the first LSTM layer is {best_hps.get('units')}.\n",
    "# The optimal dropout rate is {best_hps.get('dropout')}.\n",
    "# The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\n",
    "# \"\"\")\n",
    "\n",
    "# # Build the best model\n",
    "# model = tuner.hypermodel.build(best_hps)\n",
    "# history = model.fit(X_train, y_train, epochs=30, validation_split=0.1)\n",
    "\n",
    "# # Plot the training history\n",
    "# plt.close('all')\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('Model Loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "[0.63471645] [0.63990555]\n",
      "[0.63772094] [0.63400236]\n",
      "[0.63712704] [0.63046045]\n",
      "[0.6346474] [0.64108619]\n",
      "[0.63845384] [0.64108619]\n",
      "[0.6413568] [0.64108619]\n",
      "[0.6430212] [0.64698937]\n",
      "[0.6466515] [0.65525384]\n",
      "[0.6529305] [0.66824085]\n",
      "[0.663342] [0.66587957]\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "y_pred = model.predict(X_test)\n",
    "for i in range(10):\n",
    "  print(y_pred[i], y_test[i])\n",
    "  \n",
    "# plt.figure(figsize=(8,4))\n",
    "# plt.plot(y_test, color=\"red\", label=\"Test\")\n",
    "# plt.plot(y_pred, color=\"blue\", label=\"Prediction\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE score:  0.00047174997313834404\n",
      "RMSE score:  0.021719806010605712\n",
      "MAE score:  0.011311807733772177\n",
      "r2_score:  0.9541855553677676\n",
      "MAPE:  1.5743837143437431 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE score: \", mse)\n",
    "\n",
    "# RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE score: \", rmse)\n",
    "\n",
    "# MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"MAE score: \", mae)\n",
    "\n",
    "#R2\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"r2_score: \", r2)\n",
    "\n",
    "def mean_absolute_percentage_error(y_test, y_pred):\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_pred)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(\"MAPE: \", mape, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(y_test, color=\"red\", label=\"Test\")\n",
    "plt.plot(y_pred, color=\"blue\", label=\"Prediction\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Tomorrow's price:  1316950.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-162' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\tornado\\websocket.py:1085> exception=WebSocketClosedError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\tornado\\websocket.py\", line 1087, in wrapper\n",
      "    await fut\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\tornado\\websocket.py\", line 1089, in wrapper\n",
      "    raise WebSocketClosedError()\n",
      "tornado.websocket.WebSocketClosedError\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-165' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\tornado\\websocket.py:1085> exception=WebSocketClosedError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\tornado\\websocket.py\", line 1087, in wrapper\n",
      "    await fut\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\tornado\\websocket.py\", line 1089, in wrapper\n",
      "    raise WebSocketClosedError()\n",
      "tornado.websocket.WebSocketClosedError\n"
     ]
    }
   ],
   "source": [
    "# Get the last backcandles days' price\n",
    "last_backandles_prices = data_set_scaled[-backcandles:]\n",
    "\n",
    "# Reshape the data to match the modul input shape\n",
    "last_backandles_prices = last_backandles_prices.reshape((1, backcandles, 1))\n",
    "\n",
    "# Predict tomorrow's price\n",
    "predicted_tomorrow_price = model.predict(last_backandles_prices)\n",
    "\n",
    "# Inverse transform the predicted price to get the actual price\n",
    "predicted_tomorrow_price = sc.inverse_transform(predicted_tomorrow_price)\n",
    "\n",
    "print(\"Tomorrow's price: \", predicted_tomorrow_price[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
